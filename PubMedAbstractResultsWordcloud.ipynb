! pip install biopython

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter
import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')
import re
from Bio import Entrez

def fetch_abstracts(query, max_results=100):
    Entrez.email = "gatheringdusthere@gmail.com"  # Replace with your email
    handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results)
    record = Entrez.read(handle)
    ids = record['IdList']
    abstracts = []
    for id in ids:
        record = Entrez.efetch(db="pubmed", id=id, rettype="abstract", retmode="text")
        abstract = record.read()
        # Extracting only the abstract text from the fetched record
        abstract_text = extract_abstract_text(abstract)
        abstracts.append(abstract_text)
    return abstracts

def extract_abstract_text(abstract):
    # Extracting abstract text from the fetched record
    # You can customize this function based on the structure of your abstracts
    # Here, we assume that the abstract starts with 'ABSTRACT:' and ends with 'PMID:'
    start_index = abstract.find('ABSTRACT:') + len('ABSTRACT:')
    end_index = abstract.find('PMID:')
    abstract_text = abstract[start_index:end_index].strip()
    return abstract_text

def preprocess_text(text, query, additional_stopwords=None):
    # Add additional stopwords
    if additional_stopwords is None:
        additional_stopwords = []

    # Load NLTK stopwords
    stop_words = set(stopwords.words('english'))

    # Extract individual words from the query and add them to stopwords
    query_words = re.findall(r'\b\w+\b', query.lower())
    stop_words.update(query_words)

    # Add additional stopwords to the set
    stop_words.update(additional_stopwords)

    # Clean text by removing punctuation, stopwords, and converting to lowercase
    cleaned_text = re.sub(r'[^\w\s]', '', text)
    cleaned_text = ' '.join([word.lower() for word in cleaned_text.split() if word.lower() not in stop_words])
    return cleaned_text

def generate_wordcloud(text):
    # Generate word cloud
    wordcloud = WordCloud(width=800, height=400, background_color='white', collocations=False, 
                          max_words=200, max_font_size=100, min_font_size=10, colormap='tab20b')
    word_freq = Counter(text.split())
    wordcloud.generate_from_frequencies(word_freq)
    
    # Display word cloud
    plt.figure(figsize=(10, 10))
    plt.subplot(2, 1, 1)
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    
    # Display word frequency table
    plt.subplot(2, 1, 2)
    sorted_word_freq = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)
    top_words = [pair[0] for pair in sorted_word_freq[:20]]
    top_freqs = [pair[1] for pair in sorted_word_freq[:20]]
    plt.barh(top_words, top_freqs)
    plt.xlabel('Frequency')
    plt.ylabel('Words')
    plt.gca().invert_yaxis()
    plt.show()

def main():
    query = "hybrid sequencing bacteria complete genome analysis methods"
    additional_stopwords = ['doi', 'result', 'center', 'institute', 'science', 'sciences', 'results', 'sequences', 'sequence', 'sequencing', 
                            'patients', 'laboratory', 'study', 'using', 'analysis', 'sample', 'author', 'research',
                            'samples', 'information', 'data', 'interest', 'genome', 'university', 'pmcid']
    abstracts = fetch_abstracts(query)

    # Create a single string of all abstracts
    all_abstracts = ' '.join(abstracts)

    # Preprocess text
    cleaned_text = preprocess_text(all_abstracts, query, additional_stopwords)

    # Generate word cloud and word frequency table
    generate_wordcloud(cleaned_text)

if __name__ == "__main__":
    main()
